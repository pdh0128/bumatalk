from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain_pinecone import PineconeVectorStore
from langchain_openai import OpenAIEmbeddings
import os
from pinecone import Pinecone
from mongo import Mongo
from langchain_core.output_parsers import StrOutputParser
import requests
from datetime import datetime
from langchain_community.chat_models import ChatPerplexity
from langchain_core.prompts import ChatPromptTemplate

from langchain.globals import set_llm_cache
from langchain_community.cache import InMemoryCache

set_llm_cache(InMemoryCache())

load_dotenv()
pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
embedder = OpenAIEmbeddings()
vector_store = PineconeVectorStore(index_name=os.getenv("PINECONE_INDEX"), embedding=embedder)
pinecone_index = pc.Index(os.getenv("PINECONE_INDEX"))
db = Mongo()
def checkNone(res):
    if res is None:
        return {"output": " âŒ ê²€ìƒ‰ ì‹¤íŒ¨ âŒ"}
    return res
def student(req):
    temp = """
        ë„ˆëŠ” ë¶€ì‚°ì†Œí”„íŠ¸ì›¨ì–´ë§ˆì´ìŠ¤í„°ê³ ì˜ í•™ìƒ {name}ì— ëŒ€í•´ ì˜ ì•Œê³  ìˆëŠ” ì „ë¬¸ê°€ì•¼.
        ì£¼ì–´ì§„ ì§ˆë¬¸ì— ëŒ€í•´ í•™ìƒ {name}ì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´. 
        í•™ìƒ {name}ì— ëŒ€í•œ ì •ë³´: {Info}
        ì§ˆë¬¸: {Question}
    """
    prompt = PromptTemplate(input_variables=["name", "Info" ,"Question"], template=temp)
    query_vecter = embedder.embed_query(req)
    results = pinecone_index.query(vector=query_vecter, top_k=1, include_metadata=True)
    student_url = results['matches'][0]['id']
    student = db.getStudent(student_url)
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    chain = prompt | llm | StrOutputParser()
    res = chain.invoke(input={"name" : student['name'], "Info" : student["text"], "Question" : req})
    print(res)
    return res

def teacher(req):
    temp = """
        ë„ˆëŠ” ë¶€ì‚°ì†Œí”„íŠ¸ì›¨ì–´ë§ˆì´ìŠ¤í„°ê³ ì˜ ì„ ìƒë‹˜ {name}ì— ëŒ€í•´ ì˜ ì•Œê³  ìˆëŠ” ì „ë¬¸ê°€ì•¼.
        ì£¼ì–´ì§„ ì§ˆë¬¸ì— ëŒ€í•´ ì„ ìƒë‹˜ {name}ì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´. 
        ì„ ìƒë‹˜ {name}ì— ëŒ€í•œ ì •ë³´: {Info}
        ì§ˆë¬¸: {Question}
    """
    prompt = PromptTemplate(input_variables=["name", "Info" ,"Question"], template=temp)
    query_vecter = embedder.embed_query(req)
    results = pinecone_index.query(vector=query_vecter, top_k=1, include_metadata=True)
    teacher_url = results['matches'][0]['id']
    teacher = db.getTeacher(teacher_url)
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    chain = prompt | llm | StrOutputParser()
    res = chain.invoke(input={"name" : teacher['name'], "Info" : teacher["text"], "Question" : req})
    print(res)
    return res

def bssm(req):
    temp = """
        ë„ˆëŠ” ë¶€ì‚°ì†Œí”„íŠ¸ì›¨ì–´ë§ˆì´ìŠ¤í„°ê³ ë“±í•™êµì— ëŒ€í•œ ì „ë¬¸ê°€ì•¼.
        ì‚¬ìš©ìê°€ ë¬»ëŠ” ëª¨ë“  ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ì¹œì ˆí•˜ë©°, í•„ìš”í•œ ê²½ìš° ìƒì„¸í•œ ì •ë³´ë¥¼ ì œê³µí•´ì¤˜.
        ë‹µë³€ì€ ê°„ê²°í•˜ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•´ì•¼ í•´.
        ì§ˆë¬¸: {Question}
        ë‹µë³€:
        """
    llm = ChatPerplexity(
        temperature=0, model="sonar-pro"
    )
    prompt = PromptTemplate(input_variables=["Question"], template=temp)
    chain = prompt | llm | StrOutputParser()
    res = chain.invoke(input={"Question" : req})
    print(res)
    return res

def iDontKnow(req):
    return {"output": "ì˜ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤.\nì €ëŠ” ë¶€ì†Œë§ˆê³ ì˜ ì •ë³´ë¥¼ ì•Œë¦¬ëŠ” ë¶€ë§ˆí†¡ì…ë‹ˆë‹¤.\në‹¤ì‹œ í•œë²ˆ ë§ì”€í•´ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”? ğŸ™"}

def summary(name, text):
    text = text.strip()
    if text == "" or text is None:
        return "ë¬¸ì„œê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."
    temp = """
    ë‹¤ìŒ ë¬¸ì¥ì˜ ë‚´ìš©ì€ {name}ì— ëŒ€í•œ ë‚´ìš©ì…ë‹ˆë‹¤.
    ë‹¤ìŒ ë¬¸ì¥ì˜ ë‚´ìš©ì„ 30ë¬¸ì¥ ì´ë‚´ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.
    ê° ë¬¸ì¥ì´ ì„œë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°ë˜ë„ë¡ í•˜ê³ , ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ê¸€ì˜ ìš”ì§€ë¥¼ ì˜ ë“œëŸ¬ë‚¼ ìˆ˜ ìˆë„ë¡ ì‘ì„±í•´ ì£¼ì„¸ìš”.
    ë¬¸ì¥: {sentence}
    ìš”ì•½:
    """
    prompt = PromptTemplate(input_variables=["name" ,"sentence"], template=temp)
    llm = ChatOpenAI(temperature=0)
    chain = prompt | llm | StrOutputParser()
    res = chain.invoke(input={"name" : name, "sentence": text})
    return res


def schoolFood(req):
    url = "https://open.neis.go.kr/hub/mealServiceDietInfo"
    # today = "20240627"
    params = {
        "ATPT_OFCDC_SC_CODE": "C10",
        "SD_SCHUL_CODE": "7150658",
        "KEY": os.getenv("SCHOOLD_OPENAPI_API_KEY"),
        "Type" : "json",
        "MLSV_YMD": req
    }
    res = requests.get(url, params=params)
    if res.status_code == 200:
        # print(res.json())
        data = res.json()
        meals = food_parsing(data)
        print(meals)
        return meals
    else:
        print(f"ìš”ì²­ ì‹¤íŒ¨! ìƒíƒœ ì½”ë“œ: {res.status_code}")
        print(res.text)

def food_parsing(data):
    meals = {"ì¡°ì‹": None, "ì¤‘ì‹": None, "ì„ì‹": None}
    if "mealServiceDietInfo" in data:
        rows = data["mealServiceDietInfo"][1]["row"]
    else:
        return meals

    for meal in rows:
        meal_name = meal["MMEAL_SC_NM"]
        meals[meal_name] = {
            "ë‚ ì§œ": meal["MLSV_YMD"],
            "ë©”ë‰´": meal["DDISH_NM"].replace("<br/>", "\n"),
            "ì¹¼ë¡œë¦¬ ì •ë³´": meal["CAL_INFO"],
            "ì˜ì–‘ ì •ë³´": meal["NTR_INFO"].replace("<br/>", "\n")
        }
    return meals
if __name__ == "__main__":
    schoolFood(None)