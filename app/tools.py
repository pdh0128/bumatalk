from dotenv import load_dotenv
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain_pinecone import PineconeVectorStore
from langchain_openai import OpenAIEmbeddings
import os
from pinecone import Pinecone
from mongo import Mongo
from langchain_core.output_parsers import StrOutputParser
import requests
from datetime import datetime
from langchain_community.chat_models import ChatPerplexity
from langchain_core.prompts import ChatPromptTemplate

from langchain.globals import set_llm_cache
from langchain_community.cache import InMemoryCache

from output_parser import schoolTimeOuputParser

set_llm_cache(InMemoryCache())

load_dotenv()
pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
embedder = OpenAIEmbeddings()
vector_store = PineconeVectorStore(index_name=os.getenv("PINECONE_INDEX"), embedding=embedder)
pinecone_index = pc.Index(os.getenv("PINECONE_INDEX"))
db = Mongo()
def checkNone(res):
    if res is None:
        return {"output": " âŒ ê²€ìƒ‰ ì‹¤íŒ¨ âŒ"}
    return res
def student(req):
    temp = """
        ë„ˆëŠ” ë¶€ì‚°ì†Œí”„íŠ¸ì›¨ì–´ë§ˆì´ìŠ¤í„°ê³ ì˜ í•™ìƒ {name}ì— ëŒ€í•´ ì˜ ì•Œê³  ìˆëŠ” ì „ë¬¸ê°€ì•¼.
        ì£¼ì–´ì§„ ì§ˆë¬¸ì— ëŒ€í•´ í•™ìƒ {name}ì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´. 
        í•™ìƒ {name}ì— ëŒ€í•œ ì •ë³´: {Info}
        ì§ˆë¬¸: {Question}
    """
    prompt = PromptTemplate(input_variables=["name", "Info" ,"Question"], template=temp)
    query_vecter = embedder.embed_query(req)
    results = pinecone_index.query(vector=query_vecter, top_k=1, include_metadata=True)
    student_url = results['matches'][0]['id']
    student = db.getStudent(student_url)
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    chain = prompt | llm | StrOutputParser()
    res = chain.invoke(input={"name" : student['name'], "Info" : student["text"], "Question" : req})
    print(res)
    return res

def teacher(req):
    temp = """
        ë„ˆëŠ” ë¶€ì‚°ì†Œí”„íŠ¸ì›¨ì–´ë§ˆì´ìŠ¤í„°ê³ ì˜ ì„ ìƒë‹˜ {name}ì— ëŒ€í•´ ì˜ ì•Œê³  ìˆëŠ” ì „ë¬¸ê°€ì•¼.
        ì£¼ì–´ì§„ ì§ˆë¬¸ì— ëŒ€í•´ ì„ ìƒë‹˜ {name}ì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´. 
        ì„ ìƒë‹˜ {name}ì— ëŒ€í•œ ì •ë³´: {Info}
        ì§ˆë¬¸: {Question}
    """
    prompt = PromptTemplate(input_variables=["name", "Info" ,"Question"], template=temp)
    query_vecter = embedder.embed_query(req)
    results = pinecone_index.query(vector=query_vecter, top_k=1, include_metadata=True)
    teacher_url = results['matches'][0]['id']
    teacher = db.getTeacher(teacher_url)
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    chain = prompt | llm | StrOutputParser()
    res = chain.invoke(input={"name" : teacher['name'], "Info" : teacher["text"], "Question" : req})
    print(res)
    return res

def bssm(req):
    temp = """
        ë„ˆëŠ” ë¶€ì‚°ì†Œí”„íŠ¸ì›¨ì–´ë§ˆì´ìŠ¤í„°ê³ ë“±í•™êµì— ëŒ€í•œ ì „ë¬¸ê°€ì•¼.
        ì‚¬ìš©ìê°€ ë¬»ëŠ” ëª¨ë“  ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ì¹œì ˆí•˜ë©°, í•„ìš”í•œ ê²½ìš° ìƒì„¸í•œ ì •ë³´ë¥¼ ì œê³µí•´ì¤˜.
        ë‹µë³€ì€ ê°„ê²°í•˜ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•´ì•¼ í•´.
        ì§ˆë¬¸: {Question}
        ë‹µë³€:
        """
    llm = ChatPerplexity(
        temperature=0, model="sonar-pro"
    )
    prompt = PromptTemplate(input_variables=["Question"], template=temp)
    chain = prompt | llm | StrOutputParser()
    res = chain.invoke(input={"Question" : req})
    print(res)
    return res

def iDontKnow(req):
    return {"output": "ì˜ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤.\nì €ëŠ” ë¶€ì†Œë§ˆê³ ì˜ ì •ë³´ë¥¼ ì•Œë¦¬ëŠ” ë¶€ë§ˆí†¡ì…ë‹ˆë‹¤.\në‹¤ì‹œ í•œë²ˆ ë§ì”€í•´ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”? ğŸ™"}

def howToUse(req):
    return {
        "output" : """
    ğŸ“¢ ë¶€ë§ˆí†¡ ì´ìš© ì•ˆë‚´ ğŸ“¢
    ì•ˆë…•í•˜ì„¸ìš”!
    ë¶€ì‚°ì†Œí”„íŠ¸ì›¨ì–´ë§ˆì´ìŠ¤í„°ê³ ë“±í•™êµ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ë¶€ë§ˆí†¡ì…ë‹ˆë‹¤. ğŸ˜Š
    
    ë¶€ë§ˆí†¡ì„ ì›í™œí•˜ê²Œ ì´ìš©í•˜ë ¤ë©´ ì•„ë˜ ê·œì¹™ì„ ì§€ì¼œì£¼ì„¸ìš”!
    
    1ï¸âƒ£ ì§ˆë¬¸ì„ ëª…í™•í•˜ê²Œ í•´ì£¼ì„¸ìš”.
    ì˜ˆì‹œ:
    âŒ "ë§ˆë£¨ê°€ ë­ì•¼?"
    âœ… "êµë‚´ ì„œë¹„ìŠ¤ ë§ˆë£¨ê°€ ë­ì•¼?"
    2ï¸âƒ£ ë‹µë³€ì´ ì˜¤ê¸° ì „ì— ì¶”ê°€ ì§ˆë¬¸ì„ í•˜ì§€ ë§ˆì„¸ìš”.
    ìƒˆë¡œìš´ ì§ˆë¬¸ì„ í•˜ë©´ ëŒ€í™”ê°€ ê¼¬ì¼ ìˆ˜ ìˆì–´ìš”!
    ë§Œì•½ ê¼¬ì˜€ë‹¤ê³  ìƒê°ë˜ë©´ 2~5ë¶„ ì •ë„ ê¸°ë‹¤ë¦¬ë©´ ìë™ìœ¼ë¡œ ì •ìƒ ë³µêµ¬ë©ë‹ˆë‹¤.
    ğŸ“Œ ê¸‰ì‹ ì •ë³´ë¥¼ ë³´ë ¤ë©´ ì§ˆë¬¸ì— ë‚ ì§œë¥¼ í¬í•¨í•´ì•¼ í•´ìš”!
    ğŸ“Œ ì‹œê°„í‘œ ì •ë³´ë¥¼ ë³´ë ¤ë©´ í•™ë…„, ë°˜, ë‚ ì§œë¥¼ í¬í•¨í•´ì•¼ í•´ìš”!
    
    ì´ì œ ë¶€ë§ˆí†¡ê³¼ í•¨ê»˜ ë¶€ì‚°ì†Œí”„íŠ¸ì›¨ì–´ë§ˆì´ìŠ¤í„°ê³ ì— ëŒ€í•´ ì•Œì•„ë³´ì„¸ìš”! ğŸš€"""
}


def summary(name, text):
    text = text.strip()
    if text == "" or text is None:
        return "ë¬¸ì„œê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."
    temp = """
    ë‹¤ìŒ ë¬¸ì¥ì˜ ë‚´ìš©ì€ {name}ì— ëŒ€í•œ ë‚´ìš©ì…ë‹ˆë‹¤.
    ë‹¤ìŒ ë¬¸ì¥ì˜ ë‚´ìš©ì„ 30ë¬¸ì¥ ì´ë‚´ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.
    ê° ë¬¸ì¥ì´ ì„œë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°ë˜ë„ë¡ í•˜ê³ , ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ê¸€ì˜ ìš”ì§€ë¥¼ ì˜ ë“œëŸ¬ë‚¼ ìˆ˜ ìˆë„ë¡ ì‘ì„±í•´ ì£¼ì„¸ìš”.
    ë¬¸ì¥: {sentence}
    ìš”ì•½:
    """
    prompt = PromptTemplate(input_variables=["name" ,"sentence"], template=temp)
    llm = ChatOpenAI(temperature=0)
    chain = prompt | llm | StrOutputParser()
    res = chain.invoke(input={"name" : name, "sentence": text})
    return res


def schoolFood(req):
    url = "https://open.neis.go.kr/hub/mealServiceDietInfo"
    params = {
        "ATPT_OFCDC_SC_CODE": "C10",
        "SD_SCHUL_CODE": "7150658",
        "KEY": os.getenv("SCHOOLD_OPENAPI_API_KEY"),
        "Type" : "json",
        "MLSV_YMD": req
    }
    res = requests.get(url, params=params)
    if res.status_code == 200:
        # print(res.json())
        data = res.json()
        meals = food_parsing(data)
        print(meals)
        return meals
    else:
        print(f"ìš”ì²­ ì‹¤íŒ¨! ìƒíƒœ ì½”ë“œ: {res.status_code}")
        print(res.text)

def food_parsing(data):
    meals = {"ì¡°ì‹": None, "ì¤‘ì‹": None, "ì„ì‹": None}
    if "mealServiceDietInfo" in data:
        rows = data["mealServiceDietInfo"][1]["row"]
    else:
        return meals

    for meal in rows:
        meal_name = meal["MMEAL_SC_NM"]
        meals[meal_name] = {
            "ë‚ ì§œ": meal["MLSV_YMD"],
            "ë©”ë‰´": meal["DDISH_NM"].replace("<br/>", "\n"),
            "ì¹¼ë¡œë¦¬ ì •ë³´": meal["CAL_INFO"],
            "ì˜ì–‘ ì •ë³´": meal["NTR_INFO"].replace("<br/>", "\n")
        }
    return meals



def schoolTime(req):
    url = "https://open.neis.go.kr/hub/hisTimetable"
    data_dict = schoolTimeOuputParser.parse(req).to_dict()
    date = data_dict["date"]
    grade = data_dict["grade"]
    group = data_dict["classroom"]
    params = {
        "ATPT_OFCDC_SC_CODE": "C10",
        "SD_SCHUL_CODE": "7150658",
        "KEY": os.getenv("SCHOOLD_OPENAPI_API_KEY"),
        "Type": "json",
        "ALL_TI_YMD": date,
        "GRADE" : grade,
        "CLASS_NM" : group
    }
    res = requests.get(url, params=params)
    if res.status_code == 200:
        # print(res.json())
        data = res.json()
        time = parse_timetable(data)
        return time
    else:
        print(f"ìš”ì²­ ì‹¤íŒ¨! ìƒíƒœ ì½”ë“œ: {res.status_code}")
        print(res.text)
        return "ìš”ì²­ ì‹¤íŒ¨"

def parse_timetable(data):
    timetable = {}
    if "hisTimetable" in data:
        rows = data["hisTimetable"][1]["row"]
        for entry in rows:
            period = entry.get("PERIO", "")
            subject = entry.get("ITRT_CNTNT", "")
            timetable.update({period + "êµì‹œ" : subject})
    return timetable

def maister(req="ë§ˆì—­ëŸ‰ì— ëŒ€í•´ ì„¤ëª…í•˜ê³  ë§ˆì—­ëŸ‰ì´ ë†’ìœ¼ë©´ ì¢‹ì€ì ì— ëŒ€í•´ ë§í•´ì£¼ì„¸ìš”."):
    prompts = """
    ì—­í• :
    ë‹¹ì‹ ì€ ë§ˆì´ìŠ¤í„° ì—­ëŸ‰ ì¸ì¦ ì œë„ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë§ˆì´ìŠ¤í„° ì—­ëŸ‰(ì´í•˜ â€œë§ˆì—­ëŸ‰â€)ì— ëŒ€í•´ ê¹Šì´ ì´í•´í•˜ê³  ìˆìœ¼ë©°, ê´€ë ¨ ì§ˆë¬¸ì— ì „ë¬¸ì ì´ê³  ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.
    ë°°ê²½ ì •ë³´:
	â€¢	ë§ˆì—­ëŸ‰ì€ 2í•™ë…„ í•™ê³¼ ë°°ì • ì‹œ ì‹œí—˜ ì ìˆ˜ì™€ í•¨ê»˜ ë°˜ì˜ë©ë‹ˆë‹¤.
	â€¢	ë§ˆì—­ëŸ‰ ì ìˆ˜ê°€ ë†’ìœ¼ë©´ í•´ì™¸ í”„ë¡œê·¸ë¨ ì§€ì›(í•™êµì—ì„œ ë§ˆì—­ëŸ‰ ìš°ìˆ˜ìë¥¼ ì„ ë°œí•˜ì—¬ í•´ì™¸ë¡œ íŒŒê²¬) ë° í•™ê³¼ ì„ íƒ ë“± ë‹¤ì–‘í•œ í˜œíƒì´ ì£¼ì–´ì§‘ë‹ˆë‹¤.
	â€¢	ì•„ë˜ ì œê³µëœ ì •ë³´ëŠ” ë§ˆì—­ëŸ‰ì„ ì–»ì„ ìˆ˜ ìˆëŠ” ê¸°ì¤€ì…ë‹ˆë‹¤.
    ì •ë³´:
    {context}
    ì§€ì¹¨:
	1.	ë°˜ë“œì‹œ ìœ„ì˜ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.
	2.	ë‹µë³€ì€ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
	3.	ì¶”ê°€ ì„¤ëª…ì´ í•„ìš”í•˜ë‹¤ë©´ ê´€ë ¨ ë‚´ìš©ì„ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•˜ì—¬ ì œê³µí•˜ì„¸ìš”.
	4.	ì§ˆë¬¸ê³¼ ê´€ë ¨ ì—†ëŠ” ì¶”ê°€ì ì¸ ì •ë³´ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
	
    ì§ˆë¬¸: {Question}
    ì‘ë‹µ :
"""
    prompt = PromptTemplate.from_template(prompts)
    embedder = OpenAIEmbeddings()
    vector_store = PineconeVectorStore(index_name=os.getenv("PINECONE_pdf_INDEX"), embedding=embedder)
    llm = ChatOpenAI(model="gpt-4o-mini")
    chain = {"context": vector_store.as_retriever() | format_docs, "Question": RunnablePassthrough()
             } | prompt | llm
    res = chain.invoke(req).content
    print(res)
    return res

def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)
